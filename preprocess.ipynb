{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Thu Sep 14 10:42:04 2023\n",
    "\n",
    "@author: 51027\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9e3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39b43b7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "OpenAI.base_url = 'api.playaichat.cn'\n",
    "OpenAI.api_key = 'xxxxxx' #add you own API key\n",
    "# 1. data preparation. Load choice13k problems\n",
    "def preprocess_data(data):\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Melt the DataFrame\n",
    "    df_melted = df.melt(ignore_index=False, value_name='data')\n",
    "    \n",
    "    # Extract p and v values\n",
    "    df_melted['p'] = df_melted['data'].apply(lambda x: [item[0] for item in x]).apply(lambda x: [round(item, 4) for item in x])\n",
    "    df_melted['v'] = df_melted['data'].apply(lambda x: [item[1] for item in x])\n",
    "    \n",
    "    # Merge duplicate v values and sum their probabilities\n",
    "    def merge_v_p(v_list, p_list):\n",
    "        d = {}\n",
    "        for v, p in zip(v_list, p_list):\n",
    "            if v in d:\n",
    "                d[v] += p\n",
    "            else:\n",
    "                d[v] = p\n",
    "        return list(d.keys()), list(d.values())\n",
    "    \n",
    "    df_melted[['v', 'p']] = df_melted.apply(lambda row: merge_v_p(row['v'], row['p']), axis=1, result_type='expand')\n",
    "    \n",
    "    # Drop unnecessary columns and reset index\n",
    "    df_final = df_melted.drop(columns=['variable', 'data']).reset_index(drop=True)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5907d9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def option_prompt_generate(p,v):\n",
    "    option = ''\n",
    "\n",
    "    for i in range(len(p)):\n",
    "        if len(p)== 1:\n",
    "            option = str(v[0]) + ' dollars with ' + str(p[0]*100) + ' % chance'\n",
    "        else:\n",
    "            option = option+ str(v[i]) + ' dollars with ' + str(p[i]*100) + ' % chance'\n",
    "            \n",
    "        if i == len(p)-1 :\n",
    "            punc = '.'\n",
    "        else:\n",
    "            punc = ', '\n",
    "        option = option + punc\n",
    "    \n",
    "    return(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text, model): \n",
    "    response = OpenAI.embeddings.create(\n",
    "            model='text-embedding-3-large',\n",
    "            input=text,\n",
    "            engine= model) \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def behavioral_embedding(p,v):\n",
    "    p = np.array(p,dtype = 'float')\n",
    "    v = np.array(v, dtype = 'float')\n",
    "    ##Heuristics\n",
    "    # maximum gain\n",
    "    if np.all(v<=0):\n",
    "        max_gain = 0\n",
    "    else:\n",
    "        max_gain = v[v == np.max(v)]\n",
    "    # minimum gain\n",
    "    if np.all(v<=0):\n",
    "        min_gain = 0\n",
    "    else:\n",
    "        v_positive = v[v>=0]\n",
    "        min_gain = v[v == np.min(v_positive)]\n",
    "    # maximum loss\n",
    "    if np.all(v>=0):\n",
    "        max_loss = 0\n",
    "    else:\n",
    "        max_loss = v[v == np.min(v)]\n",
    "    # minimum loss\n",
    "    if np.all(v>=0):\n",
    "        min_loss = 0\n",
    "    else:\n",
    "        v_negative = v[v<=0]\n",
    "        min_loss = v[v == np.max(v_negative)]\n",
    "    # joint max_gain and median gain (the second high)\n",
    "    if v.size == 1:\n",
    "       if v>0:\n",
    "           joint_max_median_gain = v\n",
    "       else:\n",
    "           joint_max_median_gain = 0\n",
    "    else:\n",
    "        sorted_v = np.sort(v)[::-1]\n",
    "        if sum(sorted_v>=0)>1:\n",
    "            joint_max_median_gain = sorted_v[0] + sorted_v[1]\n",
    "        else:\n",
    "            joint_max_median_gain = 0\n",
    "            \n",
    "    # probability of maximum gain\n",
    "    if np.all(v<=0):\n",
    "        prob_max_gain = 0\n",
    "    else:\n",
    "        prob_max_gain = p[v == np.max(v)] \n",
    "    # probability of minimum gain\n",
    "    if np.all(v<=0):\n",
    "        prob_min_gain = 0\n",
    "    else:\n",
    "        v_positive = v[v>=0]\n",
    "        prob_min_gain = p[v == np.min(v_positive)]\n",
    "    # probability of maximum loss\n",
    "    if np.all(v>=0):\n",
    "        prob_max_loss = 0\n",
    "    else:\n",
    "        prob_max_loss = p[v == np.min(v)]\n",
    "    # minimum loss\n",
    "    if np.all(v>=0):\n",
    "        prob_min_loss = 0\n",
    "    else:\n",
    "        v_negative = v[v<=0]\n",
    "        prob_min_loss = p[v == np.max(v_negative)]\n",
    "    # joint probability of max_gain and median gain (the second high)\n",
    "    if v.size == 1:\n",
    "       if v>0:\n",
    "           prob_joint_max_median_gain = p\n",
    "       else:\n",
    "           prob_joint_max_median_gain = 0\n",
    "    else:\n",
    "        sorted_v = np.sort(v)[::-1]\n",
    "        if sum(sorted_v>=0)>1:\n",
    "            prob_joint_max_median_gain = p[v==sorted_v[0]] + p[v==sorted_v[1]]\n",
    "        else:\n",
    "            prob_joint_max_median_gain = 0\n",
    "            \n",
    "        \n",
    "    ####Normative\n",
    "    EV = np.dot(v,p)\n",
    "    if p.size == 1:\n",
    "        H = 0\n",
    "    else:\n",
    "        H = -sum(p*np.log2(p))\n",
    "    \n",
    "    behavioral_embedding=np.array([max_gain,min_gain,max_loss, min_loss, joint_max_median_gain,prob_max_gain,prob_min_gain,prob_max_loss,prob_min_loss,prob_joint_max_median_gain,EV,H],dtype ='object')\n",
    "    behavioral_embedding = np.hstack(behavioral_embedding)\n",
    "    return(behavioral_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f03b2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def behavioral_embedding_model(behavioral_data):\n",
    "    behavioral_data = preprocess_data(behavioral_data)\n",
    "    behavioral_embedding_dataset = np.empty((12))  \n",
    "    for i in range(behavioral_data.shape[0]):\n",
    "        tmp_data = behavioral_data.iloc[i,:]       \n",
    "        tmp_behavioral_embedding = behavioral_embedding(tmp_data['p'],tmp_data['v'])\n",
    "        behavioral_embedding_dataset = np.vstack([behavioral_embedding_dataset, tmp_behavioral_embedding])\n",
    "        \n",
    "    behavioral_embedding_dataset = behavioral_embedding_dataset[1:,]\n",
    "    behavioral_embedding_dataset = np.array(behavioral_embedding_dataset,dtype='float32')\n",
    "    return behavioral_embedding_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d85f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_embedding(behavioral_data, query):\n",
    "    if query == 'local':\n",
    "        text_problem_embeddings = np.load('result/c13k_problem_embeddings.npy')\n",
    "    elif query == 'online':\n",
    "        prompt_dataset = np.empty((0,1))   \n",
    "        for i in range(behavioral_data.shape[0]):\n",
    "            tmp_data = behavioral_data.iloc[i,:]\n",
    "            tmp_prompt = option_prompt_generate(tmp_data['p'],tmp_data['v'])\n",
    "            tmp_prompt = np.array(tmp_prompt, dtype ='object')\n",
    "            prompt_dataset = np.vstack([prompt_dataset,tmp_prompt])\n",
    "            \n",
    "        model_name = 'text-embedding-ada-002'\n",
    "        text_problem_embeddings = np.empty((prompt_dataset.shape[0],1536))\n",
    "        for i in range(prompt_dataset.shape[0]):\n",
    "            tmp_embeddings = get_embeddings(prompt_dataset[i,0],model_name)\n",
    "            text_problem_embeddings [i,:] = tmp_embeddings['data'][0]['embedding']\n",
    "    \n",
    "    text_problem_embeddings = np.array(text_problem_embeddings,dtype='float32')\n",
    "    return(text_problem_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc91049",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def str_to_number(s):\n",
    "    #s should be a series from dataframe\n",
    "    tmp_chr = str(s)\n",
    "    #remove brackets\n",
    "    tmp_chr = tmp_chr[1:-1]\n",
    "    #split the str to numbers\n",
    "    strlist = tmp_chr.split(',')\n",
    "    for i in range(len(strlist)):\n",
    "        if i == 0:\n",
    "            A = np.array(float(strlist[i]))\n",
    "        else:\n",
    "            A = np.hstack([A,float(strlist[i])])\n",
    "    return(A)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
