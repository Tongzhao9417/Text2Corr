{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987387bf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Thu Sep 14 10:16:59 2023\n",
    "\n",
    "@author: 51027\n",
    "\"\"\"\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocess import behavioral_embedding_model,text_embedding,preprocess_data\n",
    "from Data_loader import create_data_loaders\n",
    "from model import TextDecisionModel\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess import behavioral_embedding,get_embeddings,option_prompt_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c20cc1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CosineContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=0.9):\n",
    "        super(CosineContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # Cosine similarity\n",
    "        cosine_sim = nn.functional.cosine_similarity(output1, output2)\n",
    "        \n",
    "        # For similar pairs: we want the negative of (1 - cosine_sim) to make it closer to 1\n",
    "        # For dissimilar pairs: we take max(0, cosine_sim - margin) to push them apart until a certain margin\n",
    "        loss_contrastive = torch.mean(torch.mean((label) * torch.pow(1 - cosine_sim, 2)) +\n",
    "                                      torch.mean((1-label) * torch.pow(torch.clamp(cosine_sim - self.margin, min=0.0), 2)))\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d19bf53",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureLoss, self).__init__()\n",
    "        \n",
    "    \n",
    "    def forward(self, output1, output2):\n",
    "        # Standardize each dimension\n",
    "        # std1 = torch.std(output1, dim=0, keepdim=True) + 1e-8  # Avoid division by zero\n",
    "        # mean1 = torch.mean(output1, dim=0, keepdim=True)\n",
    "        # output1 = (output1 - mean1) / std1\n",
    "        \n",
    "        # std2 = torch.std(output2, dim=0, keepdim=True) + 1e-8  # Avoid division by zero\n",
    "        # mean2 = torch.mean(output2, dim=0, keepdim=True)\n",
    "        # output2 = (output2 - mean2) / std2\n",
    "        \n",
    "        feature_loss = torch.square(output1 - output2)\n",
    "        return feature_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d3ce5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 502 - {'error': {'message': 'bad response status code 502 (request id: 20240307202249128747915MHJ89VJ4)', 'type': 'upstream_error', 'param': '502', 'code': 'bad_response_status_code'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m behavioral_embeddings \u001b[38;5;241m=\u001b[39m behavioral_embedding_model(c13k_problems)\n\u001b[1;32m      3\u001b[0m c13k_problems_prepro \u001b[38;5;241m=\u001b[39m preprocess_data(c13k_problems)\n\u001b[0;32m----> 4\u001b[0m text_problem_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mtext_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc13k_problems_prepro\u001b[49m\u001b[43m,\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43monline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Experiment for Doctoral Thesis/Text2Decision/preprocess.py:194\u001b[0m, in \u001b[0;36mtext_embedding\u001b[0;34m(behavioral_data, query)\u001b[0m\n\u001b[1;32m    192\u001b[0m text_problem_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((prompt_dataset\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1536\u001b[39m))\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(prompt_dataset\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m--> 194\u001b[0m     tmp_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# text_problem_embeddings [i,:] = tmp_embeddings['data'][0]['embedding']\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     text_problem_embeddings [i,:] \u001b[38;5;241m=\u001b[39m tmp_embeddings\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39membedding\n",
      "File \u001b[0;32m~/Documents/Experiment for Doctoral Thesis/Text2Decision/preprocess.py:68\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(text, model)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embeddings\u001b[39m(text, model): \n\u001b[0;32m---> 68\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext-embedding-ada-002\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# dimensions=1536\u001b[39;49;00m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#engine= model\u001b[39;49;00m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# response = OpenAI.embeddings.create(\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m#         model='text-embedding-ada-002',\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m#         input=text,\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m#         engine= model) \u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/Experiment for Doctoral Thesis/Text2Decision/.venv/lib/python3.10/site-packages/openai/resources/embeddings.py:113\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    107\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    108\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Experiment for Doctoral Thesis/Text2Decision/.venv/lib/python3.10/site-packages/openai/_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1199\u001b[0m     )\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/Experiment for Doctoral Thesis/Text2Decision/.venv/lib/python3.10/site-packages/openai/_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Experiment for Doctoral Thesis/Text2Decision/.venv/lib/python3.10/site-packages/openai/_base_client.py:965\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m    964\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/Documents/Experiment for Doctoral Thesis/Text2Decision/.venv/lib/python3.10/site-packages/openai/_base_client.py:1013\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Experiment for Doctoral Thesis/Text2Decision/.venv/lib/python3.10/site-packages/openai/_base_client.py:965\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m    964\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/Documents/Experiment for Doctoral Thesis/Text2Decision/.venv/lib/python3.10/site-packages/openai/_base_client.py:1013\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Experiment for Doctoral Thesis/Text2Decision/.venv/lib/python3.10/site-packages/openai/_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    977\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    983\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    984\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    987\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    988\u001b[0m )\n",
      "\u001b[0;31mInternalServerError\u001b[0m: Error code: 502 - {'error': {'message': 'bad response status code 502 (request id: 20240307202249128747915MHJ89VJ4)', 'type': 'upstream_error', 'param': '502', 'code': 'bad_response_status_code'}}"
     ]
    }
   ],
   "source": [
    "c13k_problems = pd.read_json(\"data/c13k_problems.json\", orient='index')\n",
    "behavioral_embeddings = behavioral_embedding_model(c13k_problems)\n",
    "c13k_problems_prepro = preprocess_data(c13k_problems)\n",
    "text_problem_embeddings = text_embedding(c13k_problems_prepro,query = 'online')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102f3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('result/text_problem_embeddings.npy', text_problem_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb33a122",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "batch_size= 256\n",
    "train_dataloader, val_dataloader,test_dataloader = create_data_loaders(text_problem_embeddings, behavioral_embeddings, batch_size=batch_size, test_size = 0.2, contrastive = False, false_scale = 2, scale = 'outcome_scaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747062c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = JointEmbedding().to(device)\n",
    "model = TextDecisionModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a042169a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define the loss, optimizer, etc.\n",
    "criterion = FeatureLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c707a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "# cosine_similarity_threshold = 0.9 # This can be adjusted based on your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5178818",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_losses = {f\"dim_{i}\": [] for i in range(12)}\n",
    "val_feature_losses = {f\"dim_{i}\": [] for i in range(12)}\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    # true_pairs_similarity = []\n",
    "    # false_pairs_similarity = []\n",
    "    # For storing dimensional losses in an epoch\n",
    "    epoch_dimensional_losses = {f\"dim_{i}\": [] for i in range(12)}\n",
    "    val_epoch_dimensional_losses = {f\"dim_{i}\": [] for i in range(12)}\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        text_embeds = batch[\"text_embedding\"].to(device)\n",
    "        decision_embeds = batch[\"decision_embedding\"].to(device)\n",
    "        # labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # text_outputs, behavioral_outputs = model(text_embeds, decision_embeds)\n",
    "        \n",
    "        decision_pred = model(text_embeds)\n",
    "        #dimensional-wise loss to track the training\n",
    "        feature_loss = criterion(decision_pred, decision_embeds)\n",
    "        #MSE loss indeed\n",
    "        loss = torch.mean(torch.sum(feature_loss, dim=1))\n",
    "        # loss = criterion(text_outputs, behavioral_outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        for i in range(12):\n",
    "            epoch_dimensional_losses[f\"dim_{i}\"].append(feature_loss[:, i].mean().item())\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Store the average dimensional loss for this epoch\n",
    "    for i in range(12):\n",
    "        feature_losses[f\"dim_{i}\"].append(np.mean(epoch_dimensional_losses[f\"dim_{i}\"]))\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {total_loss/len(train_dataloader)}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # correct_pairs = 0\n",
    "        # total_pairs = 0\n",
    "        total_val_loss = 0\n",
    "        # true_pairs_val_similarity = []\n",
    "        # false_pairs_val_similarity = []\n",
    "\n",
    "        for batch in test_dataloader:\n",
    "            text_emb = batch[\"text_embedding\"].to(device)\n",
    "            decision_emb = batch[\"decision_embedding\"].to(device)\n",
    "            # label = batch[\"label\"].to(device)\n",
    "    \n",
    "            # text_proj, decision_proj = model(text_emb, decision_emb)\n",
    "            # cosine_sim = nn.functional.cosine_similarity(text_proj, decision_proj)\n",
    "            # loss = criterion(text_proj, decision_proj, label)\n",
    "            decision_pred = model(text_embeds)\n",
    "            val_feature_loss = criterion(decision_pred, decision_embeds)\n",
    "            loss = torch.mean(torch.sum(val_feature_loss, dim=1))\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            # # Calculate similarity for validation\n",
    "            # true_pairs_val_similarity.extend(cosine_sim[label == 1].cpu().numpy())\n",
    "            # false_pairs_val_similarity.extend(cosine_sim[label == 0].cpu().numpy())\n",
    "\n",
    "            # # Check pairs based on cosine similarity\n",
    "            # correct_pairs += ((cosine_sim > cosine_similarity_threshold) & (label == 1)).sum().item()\n",
    "            # correct_pairs += ((cosine_sim <= cosine_similarity_threshold) & (label == 0)).sum().item()\n",
    "            # total_pairs += label.size(0)\n",
    "            \n",
    "            for i in range(12):\n",
    "                val_epoch_dimensional_losses[f\"dim_{i}\"].append(val_feature_loss[:, i].mean().item())\n",
    "        \n",
    "        # Store the average dimensional loss for this epoch\n",
    "        for i in range(12):\n",
    "            val_feature_losses[f\"dim_{i}\"].append(np.mean(val_epoch_dimensional_losses[f\"dim_{i}\"]))\n",
    "                \n",
    "        # true_avg_val_sim = np.mean(true_pairs_val_similarity)\n",
    "        # false_avg_val_sim = np.mean(false_pairs_val_similarity)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - Validation Loss: {total_val_loss/len(test_dataloader)}\")\n",
    "        # print(f\"Average True Matching Similarity (Validation): {true_avg_val_sim:.2f}\")\n",
    "        # print(f\"Average False Matching Similarity (Validation): {false_avg_val_sim:.2f}\")\n",
    "        # print(f\"Difference (Validation): {true_avg_val_sim - false_avg_val_sim:.2f}\\n\")\n",
    "        # print(f\"Validation Accuracy: {correct_pairs / total_pairs * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81035929",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model.__class__.__name__ + '.pth'\n",
    "torch.save(model.state_dict(), 'result/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91921d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Visualizing the losses\n",
    "plt.figure(figsize=(6,4))\n",
    "for i in range(12):\n",
    "    plt.plot(feature_losses[f\"dim_{i}\"], label=f\"Dimension {i}\")\n",
    "plt.legend()\n",
    "plt.title(\"Dimension-wise Training Losses over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# Save the plot with a specific DPI\n",
    "plt.savefig('pic/training_loss.png', dpi=300)  # 300 DPI is a common high-resolution setting\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173952d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the losses\n",
    "plt.figure(figsize=(6,4))\n",
    "for i in range(12):\n",
    "    plt.plot(val_feature_losses[f\"dim_{i}\"], label=f\"Dimension {i}\")\n",
    "plt.legend()\n",
    "plt.title(\"Dimension-wise Validation Losses over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# Save the plot with a specific DPI\n",
    "plt.savefig('pic/val_loss.png', dpi=300)  # 300 DPI is a common high-resolution setting\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322769c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e234847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test by hand \n",
    "test_v = [1000, 0 ]\n",
    "test_p = [0.5,0.5]\n",
    "test_behavioral_embedding = behavioral_embedding(test_p, test_v)\n",
    "test_behavioral_embedding[[0,1,2,3,4,10]] =  test_behavioral_embedding[[0,1,2,3,4,10]]/1000\n",
    "test_text = option_prompt_generate(test_p, test_v)\n",
    "print(f\"test text : {test_text}\")\n",
    "model_name = 'text-embedding-ada-002'\n",
    "tmp_embeddings = get_embeddings(test_text,model_name)\n",
    "tmp_text_embeddings = tmp_embeddings.data[0].embedding\n",
    "tmp_text_embeddings = torch.tensor(tmp_text_embeddings).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    tmp_text_shared_embedding = model(tmp_text_embeddings )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8f463",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(f\"test behavioral embedding: {test_behavioral_embedding}\")\n",
    "print(f\"test text shared embedding: {tmp_text_shared_embedding}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
