{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8324a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Thu Sep 14 10:00:28 2023\n",
    "\n",
    "@author: 51027\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e8b6db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script is used to infer joint embedding for think aloud and desicison space\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocess import behavioral_embedding,text_embedding,str_to_number\n",
    "from Data_loader import create_data_loaders\n",
    "from model import TextDecisionModel\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from util import compute_similarity_distribution,decision_classifier,standardize,grouped_dimension_reduction,inference_data_preparation,visualize_data,min_max_normalize,plot_radar\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "#prepare the trained model\n",
    "# Define the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = JointEmbedding().to(device)\n",
    "model = TextDecisionModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d232cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextDecisionModel(\n",
       "  (text_proj): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.2, inplace=False)\n",
       "    (7): Linear(in_features=64, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = model.__class__.__name__ + '.pth'\n",
    "model.load_state_dict(torch.load('result/'+ model_name))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680808a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load the human dataset\n",
    "behavioral_text_embedding_dataset = np.load('result/behavioral_text_embeddings.npy', allow_pickle= True)\n",
    "##or load GPT-4 sythetic dataset\n",
    "# behavioral_text_embedding_dataset = np.load('../result/simulated_behavior_text_q_context_embeddings.npy', allow_pickle = True)\n",
    "# behavioral_text_embedding_dataset = np.load('../result/simulated_behavior_text_q_embeddings.npy', allow_pickle = True)\n",
    "behavioral_text_embedding_dataset = np.load('result/musked_simulated_behavior_text_q_embeddings.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aef870",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "option_A_embedding, option_B_embedding, think_aloud_embeddings = inference_data_preparation(behavioral_text_embedding_dataset, list(range(12, 1548)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a21693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_similarity_distribution(think_aloud_embeddings)\n",
    "# np.random.shuffle(think_aloud_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953e83a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "option_A_embedding = torch.tensor(option_A_embedding, device = device)\n",
    "option_B_embedding = torch.tensor(option_B_embedding, device = device)\n",
    "think_aloud_embeddings = torch.tensor(think_aloud_embeddings, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d32afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#infer think aloud and each option's shared embedding\n",
    "with torch.no_grad():\n",
    "    think_aloud_shared_embedding = model(think_aloud_embeddings)\n",
    "    option_A_shared_embedding = option_A_embedding\n",
    "    option_B_shared_embedding = option_B_embedding\n",
    "\n",
    "    ##above is all you need for inference; below is our piprline for anlysis. You may refer to it or build you own pipeline.\n",
    "    sim_to_A = torch.norm(think_aloud_shared_embedding - option_A_shared_embedding,dim=1)\n",
    "    sim_to_B = torch.norm(think_aloud_shared_embedding - option_B_shared_embedding,dim=1)\n",
    "    sim_to_A = think_aloud_shared_embedding - option_A_shared_embedding\n",
    "    sim_to_B = think_aloud_shared_embedding - option_B_shared_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc5f3a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "##predicting choice probability based on a geometric perspective?   \n",
    "#extract and plot histogram first\n",
    "#when choosing A\n",
    "sim_to_A = sim_to_A.cpu().numpy()\n",
    "sim_to_B = sim_to_B.cpu().numpy()\n",
    "choosing_A_idx = np.where(behavioral_text_embedding_dataset[:,2]==0)\n",
    "choosing_B_idx = np.where(behavioral_text_embedding_dataset[:,2]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e30860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histograms\n",
    "plt.hist(sim_to_A[choosing_A_idx], bins=50, alpha=0.5, label='Sim_to_A', color='blue')\n",
    "plt.hist(sim_to_B[choosing_A_idx], bins=50, alpha=0.5, label='Sim_to_B', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa15340",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Labeling and showing the plot\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Similarity in choosing A')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e86d291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histograms\n",
    "plt.hist(sim_to_A[choosing_B_idx], bins=50, alpha=0.5, label='Sim_to_A', color='blue')\n",
    "plt.hist(sim_to_B[choosing_B_idx], bins=50, alpha=0.5, label='Sim_to_B', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74506ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling and showing the plot\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Similarity in choosing B')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test statistically\n",
    "choice = np.array(behavioral_text_embedding_dataset[:,2], dtype=int)\n",
    "X = sim_to_B - sim_to_A  # your independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee99898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant to the independent variable\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b3220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "logit_model = sm.Logit(choice, X)\n",
    "result = logit_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d4936",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Print the summary\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc9ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_mean_acc_list = []\n",
    "GPT_se_acc_list = []\n",
    "##LOOCV\n",
    "#use shared embedding distance to predict?\n",
    "choice = np.array(behavioral_text_embedding_dataset[:,2], dtype =int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149044d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##baseline model:  pca on text embeddings and then logistic regression (56%)\n",
    "X = np.array(behavioral_text_embedding_dataset[:,10:1546],dtype = 'float32')\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "# 对不同数量的主成分进行实验\n",
    "max_components = 300  # 或者您想要尝试的最大主成分数\n",
    "results = []\n",
    "for n_components in range(1, max_components + 1):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X_standardized)\n",
    "\n",
    "    mean_acc, se_acc = decision_classifier(X_pca, choice, model='SVM')\n",
    "    results.append((n_components, mean_acc, se_acc))\n",
    "    print(f\"主成分数: {n_components}, 平均准确率: {mean_acc:.2f}, 标准误: {se_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1cacd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'results' is the list containing your data\n",
    "header = ['Number of Components', 'Mean Accuracy', 'Standard Error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f16da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename\n",
    "filename = \"result/pca_results.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee045b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Write data to CSV\n",
    "with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)  # write the header\n",
    "    writer.writerows(results)  # write the data rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e07305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "results = pd.read_csv(filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd180469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming results is your list of tuples\n",
    "components = results['Number of Components']\n",
    "mean_accs = results['Mean Accuracy']\n",
    "se_accs = results['Standard Error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c58025",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(components, mean_accs, '-o', label='Mean LOOCV Accuracy')\n",
    "plt.fill_between(components, \n",
    "                 [m - s for m, s in zip(mean_accs, se_accs)], \n",
    "                 [m + s for m, s in zip(mean_accs, se_accs)], \n",
    "                 color='gray', alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dbe88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Mean LOOCV Accuracy')\n",
    "plt.title('LOOCV Accuracy by Number of PCA Components')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"result/pca_accuracy.png\", format='png',bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6bad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_mean_acc_list.append(mean_acc)\n",
    "GPT_se_acc_list.append(se_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f0b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(behavioral_text_embedding_dataset[:,12:1548],dtype = 'float32')\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=100)\n",
    "X_pca = pca.fit_transform(X_standardized)\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11efcaf9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "mean_acc, se_acc = decision_classifier(X_pca, choice, model='SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf9f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1: transformed think aloud embeddings (49%) (MLP:67%)\n",
    "X = think_aloud_shared_embedding.cpu().numpy()\n",
    "mean_acc, se_acc = logistic_regression(X,choice)\n",
    "GPT_mean_acc_list.append(mean_acc)\n",
    "GPT_se_acc_list.append(se_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f48bc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#model 2: a rough relative distance (computed by cosine similarity or Euclidean distance) (58.8%) (MLP:61.1%)\n",
    "#infer think aloud and each option's shared embedding\n",
    "with torch.no_grad():\n",
    "    # think_aloud_shared_embedding, option_A_shared_embedding = model(think_aloud_embeddings, option_A_embedding)\n",
    "    # think_aloud_shared_embedding, option_B_shared_embedding = model(think_aloud_embeddings, option_B_embedding)\n",
    "    # sim_to_A = nn.functional.cosine_similarity(think_aloud_shared_embedding, option_A_shared_embedding)\n",
    "    # sim_to_B = nn.functional.cosine_similarity(think_aloud_shared_embedding, option_B_shared_embedding)\n",
    "    think_aloud_shared_embedding = model(think_aloud_embeddings)\n",
    "    option_A_shared_embedding = option_A_embedding\n",
    "    option_B_shared_embedding = option_B_embedding\n",
    "    sim_to_A = torch.norm(think_aloud_shared_embedding - option_A_shared_embedding,dim=1)\n",
    "    sim_to_B = torch.norm(think_aloud_shared_embedding - option_B_shared_embedding,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6365db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_to_A = sim_to_A.cpu().numpy()\n",
    "sim_to_B = sim_to_B.cpu().numpy()\n",
    "X= np.array(sim_to_B-sim_to_A)\n",
    "X = X.reshape((X.size, -1)) \n",
    "mean_acc, se_acc = decision_classifier(X,choice,model = 'Log')\n",
    "GPT_mean_acc_list.append(mean_acc)\n",
    "GPT_se_acc_list.append(se_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c73773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 3: relative distances on each dimension sepeaterely (therefore 16 regressors + intercept) (MLP:66.8%)\n",
    "with torch.no_grad():\n",
    "    # think_aloud_shared_embedding, option_A_shared_embedding = model(think_aloud_embeddings, option_A_embedding)\n",
    "    # think_aloud_shared_embedding, option_B_shared_embedding = model(think_aloud_embeddings, option_B_embedding)\n",
    "    # sim_to_A = nn.functional.cosine_similarity(think_aloud_shared_embedding, option_A_shared_embedding)\n",
    "    # sim_to_B = nn.functional.cosine_similarity(think_aloud_shared_embedding, option_B_shared_embedding)\n",
    "    think_aloud_shared_embedding = model(think_aloud_embeddings)\n",
    "    option_A_shared_embedding = option_A_embedding\n",
    "    option_B_shared_embedding = option_B_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a7419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "think_aloud_shared_embedding = think_aloud_shared_embedding.cpu().numpy()\n",
    "option_A_shared_embedding = option_A_shared_embedding.cpu().numpy()\n",
    "option_B_shared_embedding = option_B_shared_embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fedd1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aligned with model training, all the output should be standarized to get meaningful results.\n",
    "option_A_shared_embedding = min_max_normalize(option_A_shared_embedding,dim=0)\n",
    "option_B_shared_embedding = min_max_normalize(option_B_shared_embedding,dim=0)\n",
    "# think_aloud_shared_embedding = min_max_normalize(think_aloud_shared_embedding,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc693b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_to_A = np.abs(think_aloud_shared_embedding - option_A_shared_embedding)\n",
    "sim_to_B = np.abs(think_aloud_shared_embedding - option_B_shared_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50012084",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.array(think_aloud_shared_embedding)\n",
    "X= np.array(sim_to_B-sim_to_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3147862",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "mean_acc, se_acc = decision_classifier(X,choice,model = 'SVM')\n",
    "GPT_mean_acc_list.append(mean_acc)\n",
    "GPT_se_acc_list.append(se_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c9c916",
   "metadata": {},
   "source": [
    "Try decode the embedding with following perspectives:\n",
    "1. Can the model recover individual differences? (we have 4 types of people in GPT-4 generated think aloud)\n",
    "stadardized each dimension to get a comparable scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af42b088",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#infer think aloud and each option's shared embedding\n",
    "behavioral_text_embedding_dataset = np.load('../result/musked_simulated_behavior_text_q_embeddings.npy', allow_pickle = True)\n",
    "option_A_embedding, option_B_embedding, think_aloud_embeddings = inference_data_preparation(behavioral_text_embedding_dataset, list(range(12, 1548)))\n",
    "option_A_embedding = torch.tensor(option_A_embedding, device = device)\n",
    "option_B_embedding = torch.tensor(option_B_embedding, device = device)\n",
    "think_aloud_embeddings = torch.tensor(think_aloud_embeddings, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b504c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # think_aloud_shared_embedding, option_A_shared_embedding = model(think_aloud_embeddings, option_A_embedding)\n",
    "    # think_aloud_shared_embedding, option_B_shared_embedding = model(think_aloud_embeddings, option_B_embedding)\n",
    "    # sim_to_A = nn.functional.cosine_similarity(think_aloud_shared_embedding, option_A_shared_embedding)\n",
    "    # sim_to_B = nn.functional.cosine_similarity(think_aloud_shared_embedding, option_B_shared_embedding)\n",
    "    think_aloud_shared_embedding = model(think_aloud_embeddings)\n",
    "    option_A_shared_embedding = option_A_embedding\n",
    "    option_B_shared_embedding = option_B_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb546d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "think_aloud_shared_embedding = think_aloud_shared_embedding.cpu().numpy()\n",
    "option_A_shared_embedding = option_A_shared_embedding.cpu().numpy()\n",
    "option_B_shared_embedding = option_B_shared_embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50735197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aligned with model training, all the output should be standarized to get meaningful results.\n",
    "option_A_shared_embedding = min_max_normalize(option_A_shared_embedding,dim=0)\n",
    "option_B_shared_embedding = min_max_normalize(option_B_shared_embedding,dim=0)\n",
    "think_aloud_shared_embedding = min_max_normalize(think_aloud_shared_embedding,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be9d91",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "sim_to_A = np.abs(think_aloud_shared_embedding - option_A_shared_embedding)\n",
    "sim_to_B = np.abs(think_aloud_shared_embedding - option_B_shared_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ce535",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "distance_data = sim_to_B - sim_to_A\n",
    "distance_data = think_aloud_shared_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34d41dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioral_distance_data = np.hstack([behavioral_text_embedding_dataset[:,1:12], distance_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab7b98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9b0156",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_column_names = ['sub_id','choice', 'p1','v1','p2','v2','problem_id','think_aloud_response','word_count','question_phrase', 'type',\n",
    "                     'max_gain','min_gain','max_loss', 'min_loss', 'joint_max_median_gain','prob_max_gain','prob_min_gain','prob_max_loss','prob_min_loss','prob_joint_max_median_gain'\n",
    "                     ,'Expected Utility','Entropy']\n",
    "behavioral_distance_data = pd.DataFrame(behavioral_distance_data, columns = data_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55268bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_columns = ['max_gain','min_gain','max_loss', 'min_loss', 'joint_max_median_gain','prob_max_gain','prob_min_gain','prob_max_loss','prob_min_loss','prob_joint_max_median_gain'\n",
    "                     ,'Expected Utility','Entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d41558",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = behavioral_distance_data[['type'] + distance_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2210300",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#for different types of individuals, do their think aloud really vary larger in some typical dimensions?\n",
    "grouped_var = selected_df.groupby('type').var()\n",
    "plot_radar(grouped_var, pic_name = 'GPT-4_variances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac40d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##text embeddings pca and cluster\n",
    "method = 'PCA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0eafe",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "individual_reduced_df = grouped_dimension_reduction(behavioral_text_embedding_dataset, 3, list(range(12, 1548)), method = method, by = 1, category = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b910bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioral_joint_embedding_data = np.hstack([behavioral_text_embedding_dataset[:,1:12], sim_to_B-sim_to_A])\n",
    "individual_reduced_df = grouped_dimension_reduction(behavioral_joint_embedding_data, 3, list(range(11, 27)), method = method, by = 0, category = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9358efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the reduced_data to a DataFrame for easier handling\n",
    "reduced_df = individual_reduced_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451bf5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(reduced_df,'Category',n_dim =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c9b93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7a2e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83667a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a6685",
   "metadata": {},
   "outputs": [],
   "source": [
    "##investigate on the empirical data\n",
    "behavioral_text_embedding_dataset = np.load('../result/behavioral_text_embeddings.npy', allow_pickle= True)\n",
    "option_A_embedding, option_B_embedding, think_aloud_embeddings = inference_data_preparation(behavioral_text_embedding_dataset, list(range(10, 1546)),mode = 'decision',query = 'local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_A_embedding = torch.tensor(option_A_embedding, device = device)\n",
    "option_B_embedding = torch.tensor(option_B_embedding, device = device)\n",
    "think_aloud_embeddings = torch.tensor(think_aloud_embeddings, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde82f7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#infer think aloud and each option's shared embedding\n",
    "with torch.no_grad():\n",
    "    # think_aloud_shared_embedding, option_A_shared_embedding = model(think_aloud_embeddings, option_A_embedding)\n",
    "    # think_aloud_shared_embedding, option_B_shared_embedding = model(think_aloud_embeddings, option_B_embedding)\n",
    "    # sim_to_A = nn.functional.cosine_similarity(think_aloud_shared_embedding, option_A_shared_embedding)\n",
    "    # sim_to_B = nn.functional.cosine_similarity(think_aloud_shared_embedding, option_B_shared_embedding)\n",
    "    think_aloud_shared_embedding = model(think_aloud_embeddings)\n",
    "    option_A_shared_embedding = option_A_embedding\n",
    "    option_B_shared_embedding = option_B_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "think_aloud_shared_embedding = think_aloud_shared_embedding.cpu().numpy()\n",
    "option_A_shared_embedding = option_A_shared_embedding.cpu().numpy()\n",
    "option_B_shared_embedding = option_B_shared_embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dfd5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#align the option embedding as the neural network trained\n",
    "option_A_shared_embedding[:,[0,1,2,3,4,10]] = option_A_shared_embedding[:,[0,1,2,3,4,10]]/1000\n",
    "option_B_shared_embedding[:,[0,1,2,3,4,10]] = option_B_shared_embedding[:,[0,1,2,3,4,10]]/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29a09fd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#To evaluate variance contribution, all the dimensions should be standarized to get meaningful results.\n",
    "option_A_shared_embedding = min_max_normalize(option_A_shared_embedding,dim=0)\n",
    "option_B_shared_embedding = min_max_normalize(option_B_shared_embedding,dim=0)\n",
    "think_aloud_shared_embedding = min_max_normalize(think_aloud_shared_embedding ,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f16958",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "sim_to_A = np.abs(think_aloud_shared_embedding - option_A_shared_embedding)\n",
    "sim_to_B = np.abs(think_aloud_shared_embedding - option_B_shared_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb97dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_data = sim_to_B - sim_to_A\n",
    "distance_data = think_aloud_shared_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b10157",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioral_distance_data = np.hstack([behavioral_text_embedding_dataset[:,1:10], distance_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d64cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04edb0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_column_names = ['sub_id','choice', 'p1','v1','p2','v2','problem_id','think_aloud_response','word_count',\n",
    "                     'max_gain','min_gain','max_loss', 'min_loss', 'joint_max_median_gain','prob_max_gain','prob_min_gain','prob_max_loss','prob_min_loss','prob_joint_max_median_gain'\n",
    "                     ,'Expected Utility','Entropy']\n",
    "behavioral_distance_data = pd.DataFrame(behavioral_distance_data, columns = data_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c18c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_columns = ['max_gain','min_gain','max_loss', 'min_loss', 'joint_max_median_gain','prob_max_gain','prob_min_gain','prob_max_loss','prob_min_loss','prob_joint_max_median_gain'\n",
    "                     ,'Expected Utility','Entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b0d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = behavioral_distance_data[['sub_id'] + distance_columns]\n",
    "# selected_df['problem_id'] = selected_df['problem_id'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ac0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_var = selected_df.groupby('sub_id').var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c097c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_range = range(1, 10)  # Example: trying from 1 to 10 clusters\n",
    "sum_of_squared_distances = []\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42).fit(individual_var)\n",
    "    sum_of_squared_distances.append(kmeans.inertia_)  # .inertia_ gives the sum of squared distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c697756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Plot the elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k (Number of Clusters)')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953a9eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-mean cluster\n",
    "# Initialize KMeans\n",
    "kmeans = KMeans(n_clusters=5,random_state=42)  # specifying the number of clusters. In this example, it's 2.\n",
    "kmeans.fit(individual_var[distance_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4554fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the labels of each data point\n",
    "labels = kmeans.labels_\n",
    "labels = labels.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1807af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for different types of individuals, do their think aloud really vary larger in some typical dimensions?\n",
    "individual_var['type'] = labels\n",
    "type_counts = individual_var['type'].value_counts().sort_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "type_counts.plot(kind='bar')\n",
    "plt.title('Counts of Observation Types')\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)  # Rotates labels to make them readable\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8d279",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "grouped_var = individual_var.groupby('type').mean()\n",
    "plot_radar(grouped_var,'Human_variances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2c4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Human_mean_acc_list = []\n",
    "Human_se_acc_list = []\n",
    "##LOOCV\n",
    "#use shared embedding distance to predict?\n",
    "choice = np.array(behavioral_text_embedding_dataset[:,2], dtype =int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8182b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##baseline model:  pca on text embeddings and then logistic regression (56%)\n",
    "X = np.array(behavioral_text_embedding_dataset[:,10:1546],dtype = 'float32')\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942678ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_standardized)\n",
    "X_pca = pca.transform(X_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b26368",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "mean_acc, se_acc = decision_classifier(X_pca,choice,model='SVM')\n",
    "Human_mean_acc_list.append(mean_acc)\n",
    "Human_se_acc_list.append(se_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a04831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1: transformed think aloud embeddings (MLP:57%)\n",
    "X = think_aloud_shared_embedding\n",
    "choice = np.array(behavioral_text_embedding_dataset[:,2], dtype =int)\n",
    "mean_acc, se_acc = decision_classifier(X,choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de31de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Human_mean_acc_list.append(mean_acc)\n",
    "Human_se_acc_list.append(se_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ce7f1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#model 2: a rough relative distance (computed by cosine similarity or Euclidean distance)) (MLP:57.8%)\n",
    "#infer think aloud and each option's shared embedding\n",
    "with torch.no_grad():\n",
    "    # think_aloud_shared_embedding, option_A_shared_embedding = model(think_aloud_embeddings, option_A_embedding)\n",
    "    # think_aloud_shared_embedding, option_B_shared_embedding = model(think_aloud_embeddings, option_B_embedding)\n",
    "    # sim_to_A = nn.functional.cosine_similarity(think_aloud_shared_embedding, option_A_shared_embedding)\n",
    "    # sim_to_B = nn.functional.cosine_similarity(think_aloud_shared_embedding, option_B_shared_embedding)\n",
    "    think_aloud_shared_embedding = model(think_aloud_embeddings)\n",
    "    option_A_shared_embedding = model(option_A_embedding)\n",
    "    option_B_shared_embedding = model(option_B_embedding)\n",
    "    sim_to_A = torch.norm(think_aloud_shared_embedding - option_A_shared_embedding,dim=1)\n",
    "    sim_to_B = torch.norm(think_aloud_shared_embedding - option_B_shared_embedding,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46f79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_to_A = sim_to_A.cpu().numpy()\n",
    "sim_to_B = sim_to_B.cpu().numpy()\n",
    "X= np.array(sim_to_B-sim_to_A)\n",
    "X = X.reshape((X.size, -1)) \n",
    "mean_acc, se_acc = decision_classifier(X,choice)\n",
    "Human_mean_acc_list.append(mean_acc)\n",
    "Human_se_acc_list.append(se_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1a3d4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#model 3: relative distances on each dimension sepeaterely (therefore 12 regressors + intercept) (MLP:67.1%)\n",
    "with torch.no_grad():\n",
    "    # think_aloud_shared_embedding, option_A_shared_embedding = model(think_aloud_embeddings, option_A_embedding)\n",
    "    # think_aloud_shared_embedding, option_B_shared_embedding = model(think_aloud_embeddings, option_B_embedding)\n",
    "    # sim_to_A = think_aloud_shared_embedding - option_A_shared_embedding\n",
    "    # sim_to_B = think_aloud_shared_embedding - option_B_shared_embedding\n",
    "    think_aloud_shared_embedding = model(think_aloud_embeddings)\n",
    "    option_A_shared_embedding = option_A_embedding\n",
    "    option_B_shared_embedding = option_B_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d36ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_A_shared_embedding = option_A_shared_embedding.cpu().numpy()\n",
    "option_B_shared_embedding = option_B_shared_embedding.cpu().numpy()\n",
    "think_aloud_shared_embedding = think_aloud_shared_embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c3096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#align the option embedding as the neural network trained\n",
    "option_A_shared_embedding[:,[0,1,2,3,4,10]] = option_A_shared_embedding[:,[0,1,2,3,4,10]]/1000\n",
    "option_B_shared_embedding[:,[0,1,2,3,4,10]] = option_B_shared_embedding[:,[0,1,2,3,4,10]]/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57253b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aligned with model training, all the output should be standarized to get meaningful results.\n",
    "option_A_shared_embedding = min_max_normalize(option_A_shared_embedding,dim=0)\n",
    "option_B_shared_embedding = min_max_normalize(option_B_shared_embedding,dim=0)\n",
    "# think_aloud_shared_embedding = min_max_normalize(think_aloud_shared_embedding,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08171403",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_to_A = np.abs(think_aloud_shared_embedding - option_A_shared_embedding)\n",
    "sim_to_B = np.abs(think_aloud_shared_embedding - option_B_shared_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d2088",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.array(sim_to_B-sim_to_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e79c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc, se_acc = decision_classifier(X,choice,model = 'Log')\n",
    "Human_mean_acc_list.append(mean_acc)\n",
    "Human_se_acc_list.append(se_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "###adding another method\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5648e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b3f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_name = ['maximum-gain','minimum-gain','maximum-loss','minimum-loss','maxium-plus-median-gain',\n",
    "            'maximum-gain probability','minimum-gain probability','maximum-loss probability',\n",
    "            'minimum-loss probability','maxium-plus-median-gain probability','expected-utility','uncertainty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a1cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_name = ['preferred', 'neutral', 'averse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798eefdb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "behavioral_text_q_data = np.load('result/behavioral_text_q_data.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b3fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(702,behavioral_text_q_data.shape[0]):\n",
    "    tmp_context =  behavioral_text_q_data[i,10]\n",
    "    tmp_think_aloud = 'Think Aloud response: ' + behavioral_text_q_data[i,8]\n",
    "    tmp_prompt = tmp_context + tmp_think_aloud\n",
    "    tmp_score = []\n",
    "    for tmp_dim in dim_name:\n",
    "        tmp_labels = []\n",
    "        for tmp_opt in opt_name:\n",
    "            tmp_labels.append(tmp_dim + ' ' + tmp_opt)\n",
    "        output = classifier(tmp_prompt,\n",
    "            candidate_labels = tmp_labels,\n",
    "            multi_label=True,\n",
    "        )\n",
    "        # Initialize a dictionary to store the scores with key terms\n",
    "        score_map = {'preferred': None, 'neutral': None, 'averse': None}\n",
    "    \n",
    "        # Loop through the labels and scores and map them\n",
    "        for label, score in zip(output['labels'], output['scores']):\n",
    "            if 'preferred' in label:\n",
    "                score_map['preferred'] = score\n",
    "            elif 'neutral' in label:\n",
    "                score_map['neutral'] = score\n",
    "            elif 'averse' in label:\n",
    "                score_map['averse'] = score\n",
    "        \n",
    "        # Extract the scores in the desired order\n",
    "        reordered_scores = [score_map[key] for key in ['preferred', 'neutral', 'averse']]\n",
    "        tmp_score = tmp_score + reordered_scores\n",
    "        \n",
    "    if i ==0:\n",
    "        dim_score = np.array(tmp_score)\n",
    "    else:\n",
    "        dim_score = np.vstack([dim_score,np.array(tmp_score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('result/naive_machine_coding_score.npy',dim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe843578",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_score = np.load('result/naive_machine_coding_score.npy')\n",
    "#model 4 naive machine coding to think aloud (0.644+_0.012)\n",
    "choice = np.array(behavioral_text_q_data[:,2], dtype =int)\n",
    "X = dim_score\n",
    "mean_acc, se_acc = decision_classifier(X,choice,model='Log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec921253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3f2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "###load a word fraction model to predict choice\n",
    "df_merged_fraction= pd.read_csv('../result/df_merged_fraction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75090c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from category to integer (57%)\n",
    "choice_mapping = {'A': 0, 'B': 1}\n",
    "choice = df_merged_fraction['choice'].map(choice_mapping)\n",
    "X = df_merged_fraction[['va','vb','pa','pb']]\n",
    "X = np.column_stack([\n",
    "    df_merged_fraction['vb'] - df_merged_fraction['va'],\n",
    "    df_merged_fraction['pb'] - df_merged_fraction['pa']\n",
    "])\n",
    "mean_acc, se_acc = decision_classifier(X,choice,model='Log')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
