{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from openai import OpenAI\n",
    "from preprocess import option_prompt_generate,preprocess_data,behavioral_embedding \n",
    "#preprocess中暂时废弃client，text embedding，behavioral_embedding_model\n",
    "from Data_loader import create_data_loaders\n",
    "from model import TextDecisionModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c13k_problems_raw = pd.read_json(\"data/c13k_problems.json\", orient='index')\n",
    "# c13k_problems_raw = pd.read_json(\"./result/c13k_problems.json\", orient='index')\n",
    "c13k_problems = preprocess_data(c13k_problems_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url='https://api.tutujin.com/v1',\n",
    "    api_key='sk-O1OLuehmNmUpIbgN4e8dCdCb4299450e90F02a3845E6E8F0') #add you own API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建问题文本\n",
    "prompt_list = []  \n",
    "for i in range(c13k_problems.shape[0]): #逐条处理\n",
    "    tmp_data = c13k_problems.iloc[i,:]\n",
    "    tmp_prompt = option_prompt_generate(tmp_data['p'],tmp_data['v'])\n",
    "    tmp_prompt = np.array(tmp_prompt, dtype ='object')\n",
    "    prompt_list.append(tmp_prompt)\n",
    "\n",
    "# 循环结束后，一次性将所有prompt合并为numpy数组\n",
    "prompt_dataset = np.vstack(prompt_list)\n",
    "\n",
    "# 如果需要保持二维结构且列数为1，可以添加以下代码：\n",
    "if len(prompt_dataset.shape) == 1:\n",
    "    prompt_dataset = prompt_dataset.reshape(-1, 1)\n",
    "\n",
    "# 优化后时间缩短：7.9s to 1.0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now is batch 1000\n",
      "now is batch 2000\n",
      "now is batch 3000\n",
      "now is batch 4000\n",
      "now is batch 5000\n",
      "now is batch 6000\n",
      "now is batch 7000\n",
      "now is batch 8000\n",
      "now is batch 9000\n",
      "now is batch 10000\n",
      "now is batch 11000\n",
      "now is batch 12000\n",
      "now is batch 13000\n",
      "now is batch 14000\n",
      "now is batch 15000\n",
      "now is batch 16000\n",
      "now is batch 17000\n",
      "now is batch 18000\n",
      "now is batch 19000\n",
      "now is batch 20000\n",
      "now is batch 21000\n",
      "now is batch 22000\n",
      "now is batch 23000\n",
      "now is batch 24000\n",
      "now is batch 25000\n",
      "now is batch 26000\n",
      "now is batch 27000\n",
      "now is batch 28000\n",
      "now is batch 29000\n",
      "now is batch 30000\n"
     ]
    }
   ],
   "source": [
    "# 批量获取文本嵌入\n",
    "input_texts = prompt_dataset[:, 0].tolist()  # 转换为Python列表\n",
    "batch_size = 1000  # 根据API限制和系统资源调整合适的批量大小\n",
    "embeddings_batches = []\n",
    "\n",
    "for i in range(0, len(input_texts), batch_size):\n",
    "    batch_texts = input_texts[i:i + batch_size]\n",
    "    \n",
    "    tmp_embeddings_batch = client.embeddings.create(\n",
    "        model='text-embedding-ada-002',\n",
    "        input=batch_texts,\n",
    "        # dimensions=1536\n",
    "        )\n",
    "        \n",
    "    # 将批量结果添加到列表中\n",
    "    embeddings_batches.append(tmp_embeddings_batch.data)\n",
    "    print(\"now is batch\",i+batch_size)\n",
    "\n",
    "# 合并所有批次的嵌入结果\n",
    "all_embeddings = [emb.embedding for batch in embeddings_batches for emb in batch]\n",
    "\n",
    "# 将嵌入结果转换为numpy数组\n",
    "text_problem_embeddings = np.array(all_embeddings, dtype=np.float32).reshape(prompt_dataset.shape[0], 1536)\n",
    "\n",
    "# batch_size = 5时，时间缩短35.8s to 5.0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01751892, -0.00901634, -0.00247082, ..., -0.01165573,\n",
       "         0.00282884, -0.01442357],\n",
       "       [-0.01565006, -0.02233857, -0.00347815, ..., -0.00338671,\n",
       "         0.01908576, -0.01930784],\n",
       "       [ 0.01596104, -0.03506856, -0.01965883, ..., -0.01489876,\n",
       "        -0.00076729, -0.02201197],\n",
       "       ...,\n",
       "       [ 0.00505597, -0.02872606, -0.00178881, ..., -0.00494427,\n",
       "         0.0136797 , -0.02304918],\n",
       "       [ 0.01087554, -0.02887958, -0.00481435, ..., -0.00595021,\n",
       "        -0.0040669 , -0.01366949],\n",
       "       [ 0.01734488, -0.02502469, -0.0001904 , ..., -0.0190428 ,\n",
       "         0.00752308, -0.02537734]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(\"./result/refresh_text_problem_embeddings.npy\", text_problem_embeddings)\n",
    "np.load('./result/refresh_text_problem_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#origin = np.load('./result/text_problem_embeddings.npy')\n",
    "text_problem_embeddings = np.load('./result/refresh_text_problem_embeddings.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始行为嵌入向量列表\n",
    "behavioral_embedding_dataset = []\n",
    "\n",
    "for i in range(c13k_problems.shape[0]):\n",
    "    # 提取单个行为数据\n",
    "    tmp_data = c13k_problems.iloc[i, :]\n",
    "    # 计算行为嵌入向量\n",
    "    tmp_behavioral_embedding = behavioral_embedding(tmp_data['p'], tmp_data['v'])\n",
    "    # 将行为嵌入向量添加到列表中\n",
    "    behavioral_embedding_dataset.append(tmp_behavioral_embedding)\n",
    "\n",
    "# 将嵌入向量列表转换为numpy数组，并指定数据类型为float32\n",
    "behavioral_embedding_dataset = np.array(behavioral_embedding_dataset, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"result/refresh_behavioral_embeddings.npy\", behavioral_embedding_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#origin = np.load('./result/c13k_behav_embeddings.npy')\n",
    "behavioral_embeddings = np.load('./result/refresh_behavioral_embeddings.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 256\n",
    "train_dataloader, val_dataloader,test_dataloader = create_data_loaders(text_problem_embeddings, behavioral_embeddings, batch_size=batch_size, test_size = 0.2, contrastive = False, false_scale = 2, scale = 'outcome_scaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=0.9):\n",
    "        super(CosineContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # Cosine similarity\n",
    "        cosine_sim = nn.functional.cosine_similarity(output1, output2)\n",
    "        \n",
    "        # For similar pairs: we want the negative of (1 - cosine_sim) to make it closer to 1\n",
    "        # For dissimilar pairs: we take max(0, cosine_sim - margin) to push them apart until a certain margin\n",
    "        loss_contrastive = torch.mean(torch.mean((label) * torch.pow(1 - cosine_sim, 2)) +\n",
    "                                      torch.mean((1-label) * torch.pow(torch.clamp(cosine_sim - self.margin, min=0.0), 2)))\n",
    "        return loss_contrastive\n",
    "    \n",
    "class FeatureLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FeatureLoss, self).__init__()\n",
    "        \n",
    "    \n",
    "    def forward(self, output1, output2):\n",
    "        # Standardize each dimension\n",
    "        # std1 = torch.std(output1, dim=0, keepdim=True) + 1e-8  # Avoid division by zero\n",
    "        # mean1 = torch.mean(output1, dim=0, keepdim=True)\n",
    "        # output1 = (output1 - mean1) / std1\n",
    "        \n",
    "        # std2 = torch.std(output2, dim=0, keepdim=True) + 1e-8  # Avoid division by zero\n",
    "        # mean2 = torch.mean(output2, dim=0, keepdim=True)\n",
    "        # output2 = (output2 - mean2) / std2\n",
    "        \n",
    "        feature_loss = torch.square(output1 - output2)\n",
    "        return feature_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = JointEmbedding().to(device)\n",
    "model = TextDecisionModel().to(device)\n",
    "# Define the loss, optimizer, etc.\n",
    "criterion = FeatureLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 200\n",
    "cosine_similarity_threshold = 0.9 # This can be adjusted based on your needs\n",
    "\n",
    "feature_losses = {f\"dim_{i}\": [] for i in range(12)}\n",
    "val_feature_losses = {f\"dim_{i}\": [] for i in range(12)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m text_embeds \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m decision_embeds \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecision_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 13\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# text_outputs, behavioral_outputs = model(text_embeds, decision_embeds)\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    # true_pairs_similarity = []\n",
    "    # false_pairs_similarity = []\n",
    "    # For storing dimensional losses in an epoch\n",
    "    epoch_dimensional_losses = {f\"dim_{i}\": [] for i in range(12)}\n",
    "    val_epoch_dimensional_losses = {f\"dim_{i}\": [] for i in range(12)}\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        text_embeds = batch[\"text_embedding\"].to(device)\n",
    "        decision_embeds = batch[\"decision_embedding\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # text_outputs, behavioral_outputs = model(text_embeds, decision_embeds)\n",
    "        \n",
    "        decision_pred = model(text_embeds)\n",
    "        #dimensional-wise loss to track the training\n",
    "        feature_loss = criterion(decision_pred, decision_embeds)\n",
    "        #MSE loss indeed\n",
    "        loss = torch.mean(torch.sum(feature_loss, dim=1))\n",
    "        # loss = criterion(text_outputs, behavioral_outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        for i in range(12):\n",
    "            epoch_dimensional_losses[f\"dim_{i}\"].append(feature_loss[:, i].mean().item())\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Store the average dimensional loss for this epoch\n",
    "    for i in range(12):\n",
    "        feature_losses[f\"dim_{i}\"].append(np.mean(epoch_dimensional_losses[f\"dim_{i}\"]))\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {total_loss/len(train_dataloader)}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct_pairs = 0\n",
    "        total_pairs = 0\n",
    "        total_val_loss = 0\n",
    "        # true_pairs_val_similarity = []\n",
    "        # false_pairs_val_similarity = []\n",
    "\n",
    "        for batch in test_dataloader:\n",
    "            text_emb = batch[\"text_embedding\"].to(device)\n",
    "            decision_emb = batch[\"decision_embedding\"].to(device)\n",
    "            label = batch[\"label\"].to(device)\n",
    "    \n",
    "            text_proj = model(text_emb)\n",
    "            cosine_sim = nn.functional.cosine_similarity(text_proj, decision_emb)\n",
    "            # loss = criterion(text_proj, decision_proj, label)\n",
    "            decision_pred = model(text_embeds)\n",
    "            val_feature_loss = criterion(decision_pred, decision_embeds)\n",
    "            loss = torch.mean(torch.sum(val_feature_loss, dim=1))\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            # # Calculate similarity for validation\n",
    "            # true_pairs_val_similarity.extend(cosine_sim[label == 1].cpu().numpy())\n",
    "            # false_pairs_val_similarity.extend(cosine_sim[label == 0].cpu().numpy())\n",
    "\n",
    "            # # Check pairs based on cosine similarity\n",
    "            correct_pairs += ((cosine_sim > cosine_similarity_threshold) & (label == 1)).sum().item()\n",
    "            correct_pairs += ((cosine_sim <= cosine_similarity_threshold) & (label == 0)).sum().item()\n",
    "            total_pairs += label.size(0)\n",
    "            \n",
    "            for i in range(12):\n",
    "                val_epoch_dimensional_losses[f\"dim_{i}\"].append(val_feature_loss[:, i].mean().item())\n",
    "        \n",
    "        # Store the average dimensional loss for this epoch\n",
    "        for i in range(12):\n",
    "            val_feature_losses[f\"dim_{i}\"].append(np.mean(val_epoch_dimensional_losses[f\"dim_{i}\"]))\n",
    "                \n",
    "        # true_avg_val_sim = np.mean(true_pairs_val_similarity)\n",
    "        # false_avg_val_sim = np.mean(false_pairs_val_similarity)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - Validation Loss: {total_val_loss/len(test_dataloader)}\")\n",
    "        # print(f\"Average True Matching Similarity (Validation): {true_avg_val_sim:.2f}\")\n",
    "        # print(f\"Average False Matching Similarity (Validation): {false_avg_val_sim:.2f}\")\n",
    "        # print(f\"Difference (Validation): {true_avg_val_sim - false_avg_val_sim:.2f}\\n\")\n",
    "        print(f\"Validation Accuracy: {correct_pairs / total_pairs * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model.__class__.__name__ + '.pth'\n",
    "torch.save(model.state_dict(), 'result/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the losses\n",
    "plt.figure(figsize=(6,4))\n",
    "for i in range(12):\n",
    "    plt.plot(feature_losses[f\"dim_{i}\"], label=f\"Dimension {i}\")\n",
    "plt.legend()\n",
    "plt.title(\"Dimension-wise Training Losses over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# Save the plot with a specific DPI\n",
    "plt.savefig('pic/training_loss.png', dpi=300)  # 300 DPI is a common high-resolution setting\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the losses\n",
    "plt.figure(figsize=(6,4))\n",
    "for i in range(12):\n",
    "    plt.plot(val_feature_losses[f\"dim_{i}\"], label=f\"Dimension {i}\")\n",
    "plt.legend()\n",
    "plt.title(\"Dimension-wise Validation Losses over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# Save the plot with a specific DPI\n",
    "plt.savefig('pic/val_loss.png', dpi=300)  # 300 DPI is a common high-resolution setting\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test by hand \n",
    "test_v = [1000, 0 ]\n",
    "test_p = [0.5,0.5]\n",
    "test_behavioral_embedding = behavioral_embedding(test_p, test_v)\n",
    "test_behavioral_embedding[[0,1,2,3,4,10]] =  test_behavioral_embedding[[0,1,2,3,4,10]]/1000\n",
    "test_text = option_prompt_generate(test_p, test_v)\n",
    "print(f\"test text : {test_text}\")\n",
    "tmp_embeddings = client.embeddings.create(\n",
    "            model='text-embedding-3-large',\n",
    "            input=test_text,\n",
    "            dimensions=1536)\n",
    "tmp_text_embeddings = tmp_embeddings.data[0].embedding\n",
    "tmp_text_embeddings = torch.tensor(tmp_text_embeddings).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    tmp_text_shared_embedding = model(tmp_text_embeddings )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"test behavioral embedding: {test_behavioral_embedding}\")\n",
    "print(f\"test text shared embedding: {tmp_text_shared_embedding}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
