{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987387bf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Thu Sep 14 10:16:59 2023\n",
    "\n",
    "@author: 51027\n",
    "\"\"\"\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocess import behavioral_embedding_model,text_embedding,preprocess_data,text_embedding_multiple\n",
    "from Data_loader import create_data_loaders\n",
    "from model import TextDecisionModel\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess import behavioral_embedding,get_embeddings,option_prompt_generate\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c20cc1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CosineContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=0.9):\n",
    "        super(CosineContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # Cosine similarity\n",
    "        cosine_sim = nn.functional.cosine_similarity(output1, output2)\n",
    "        \n",
    "        # For similar pairs: we want the negative of (1 - cosine_sim) to make it closer to 1\n",
    "        # For dissimilar pairs: we take max(0, cosine_sim - margin) to push them apart until a certain margin\n",
    "        loss_contrastive = torch.mean(torch.mean((label) * torch.pow(1 - cosine_sim, 2)) +\n",
    "                                      torch.mean((1-label) * torch.pow(torch.clamp(cosine_sim - self.margin, min=0.0), 2)))\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d19bf53",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureLoss, self).__init__()\n",
    "        \n",
    "    \n",
    "    def forward(self, output1, output2):\n",
    "        # Standardize each dimension\n",
    "        # std1 = torch.std(output1, dim=0, keepdim=True) + 1e-8  # Avoid division by zero\n",
    "        # mean1 = torch.mean(output1, dim=0, keepdim=True)\n",
    "        # output1 = (output1 - mean1) / std1\n",
    "        \n",
    "        # std2 = torch.std(output2, dim=0, keepdim=True) + 1e-8  # Avoid division by zero\n",
    "        # mean2 = torch.mean(output2, dim=0, keepdim=True)\n",
    "        # output2 = (output2 - mean2) / std2\n",
    "        \n",
    "        feature_loss = torch.square(output1 - output2)\n",
    "        return feature_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7d3ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c13k_problems = pd.read_json(\"data/c13k_problems.json\", orient='index')\n",
    "behavioral_embeddings = behavioral_embedding_model(c13k_problems)\n",
    "c13k_problems_prepro = preprocess_data(c13k_problems)\n",
    "pool = multiprocessing.Pool(processes=4)\n",
    "text_problem_embeddings = pool.starmap(text_embedding_multiple, c13k_problems_prepro)\n",
    "# text_problem_embeddings = text_embedding(c13k_problems_prepro,query = 'online')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102f3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('result/text_problem_embeddings.npy', text_problem_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb33a122",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "batch_size= 256\n",
    "train_dataloader, val_dataloader,test_dataloader = create_data_loaders(text_problem_embeddings, behavioral_embeddings, batch_size=batch_size, test_size = 0.2, contrastive = False, false_scale = 2, scale = 'outcome_scaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747062c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = JointEmbedding().to(device)\n",
    "model = TextDecisionModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a042169a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define the loss, optimizer, etc.\n",
    "criterion = FeatureLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c707a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "# cosine_similarity_threshold = 0.9 # This can be adjusted based on your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5178818",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_losses = {f\"dim_{i}\": [] for i in range(12)}\n",
    "val_feature_losses = {f\"dim_{i}\": [] for i in range(12)}\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    # true_pairs_similarity = []\n",
    "    # false_pairs_similarity = []\n",
    "    # For storing dimensional losses in an epoch\n",
    "    epoch_dimensional_losses = {f\"dim_{i}\": [] for i in range(12)}\n",
    "    val_epoch_dimensional_losses = {f\"dim_{i}\": [] for i in range(12)}\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        text_embeds = batch[\"text_embedding\"].to(device)\n",
    "        decision_embeds = batch[\"decision_embedding\"].to(device)\n",
    "        # labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # text_outputs, behavioral_outputs = model(text_embeds, decision_embeds)\n",
    "        \n",
    "        decision_pred = model(text_embeds)\n",
    "        #dimensional-wise loss to track the training\n",
    "        feature_loss = criterion(decision_pred, decision_embeds)\n",
    "        #MSE loss indeed\n",
    "        loss = torch.mean(torch.sum(feature_loss, dim=1))\n",
    "        # loss = criterion(text_outputs, behavioral_outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        for i in range(12):\n",
    "            epoch_dimensional_losses[f\"dim_{i}\"].append(feature_loss[:, i].mean().item())\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Store the average dimensional loss for this epoch\n",
    "    for i in range(12):\n",
    "        feature_losses[f\"dim_{i}\"].append(np.mean(epoch_dimensional_losses[f\"dim_{i}\"]))\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {total_loss/len(train_dataloader)}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # correct_pairs = 0\n",
    "        # total_pairs = 0\n",
    "        total_val_loss = 0\n",
    "        # true_pairs_val_similarity = []\n",
    "        # false_pairs_val_similarity = []\n",
    "\n",
    "        for batch in test_dataloader:\n",
    "            text_emb = batch[\"text_embedding\"].to(device)\n",
    "            decision_emb = batch[\"decision_embedding\"].to(device)\n",
    "            # label = batch[\"label\"].to(device)\n",
    "    \n",
    "            # text_proj, decision_proj = model(text_emb, decision_emb)\n",
    "            # cosine_sim = nn.functional.cosine_similarity(text_proj, decision_proj)\n",
    "            # loss = criterion(text_proj, decision_proj, label)\n",
    "            decision_pred = model(text_embeds)\n",
    "            val_feature_loss = criterion(decision_pred, decision_embeds)\n",
    "            loss = torch.mean(torch.sum(val_feature_loss, dim=1))\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            # # Calculate similarity for validation\n",
    "            # true_pairs_val_similarity.extend(cosine_sim[label == 1].cpu().numpy())\n",
    "            # false_pairs_val_similarity.extend(cosine_sim[label == 0].cpu().numpy())\n",
    "\n",
    "            # # Check pairs based on cosine similarity\n",
    "            # correct_pairs += ((cosine_sim > cosine_similarity_threshold) & (label == 1)).sum().item()\n",
    "            # correct_pairs += ((cosine_sim <= cosine_similarity_threshold) & (label == 0)).sum().item()\n",
    "            # total_pairs += label.size(0)\n",
    "            \n",
    "            for i in range(12):\n",
    "                val_epoch_dimensional_losses[f\"dim_{i}\"].append(val_feature_loss[:, i].mean().item())\n",
    "        \n",
    "        # Store the average dimensional loss for this epoch\n",
    "        for i in range(12):\n",
    "            val_feature_losses[f\"dim_{i}\"].append(np.mean(val_epoch_dimensional_losses[f\"dim_{i}\"]))\n",
    "                \n",
    "        # true_avg_val_sim = np.mean(true_pairs_val_similarity)\n",
    "        # false_avg_val_sim = np.mean(false_pairs_val_similarity)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - Validation Loss: {total_val_loss/len(test_dataloader)}\")\n",
    "        # print(f\"Average True Matching Similarity (Validation): {true_avg_val_sim:.2f}\")\n",
    "        # print(f\"Average False Matching Similarity (Validation): {false_avg_val_sim:.2f}\")\n",
    "        # print(f\"Difference (Validation): {true_avg_val_sim - false_avg_val_sim:.2f}\\n\")\n",
    "        # print(f\"Validation Accuracy: {correct_pairs / total_pairs * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81035929",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model.__class__.__name__ + '.pth'\n",
    "torch.save(model.state_dict(), 'result/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91921d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Visualizing the losses\n",
    "plt.figure(figsize=(6,4))\n",
    "for i in range(12):\n",
    "    plt.plot(feature_losses[f\"dim_{i}\"], label=f\"Dimension {i}\")\n",
    "plt.legend()\n",
    "plt.title(\"Dimension-wise Training Losses over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# Save the plot with a specific DPI\n",
    "plt.savefig('pic/training_loss.png', dpi=300)  # 300 DPI is a common high-resolution setting\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173952d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the losses\n",
    "plt.figure(figsize=(6,4))\n",
    "for i in range(12):\n",
    "    plt.plot(val_feature_losses[f\"dim_{i}\"], label=f\"Dimension {i}\")\n",
    "plt.legend()\n",
    "plt.title(\"Dimension-wise Validation Losses over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# Save the plot with a specific DPI\n",
    "plt.savefig('pic/val_loss.png', dpi=300)  # 300 DPI is a common high-resolution setting\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322769c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e234847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test by hand \n",
    "test_v = [1000, 0 ]\n",
    "test_p = [0.5,0.5]\n",
    "test_behavioral_embedding = behavioral_embedding(test_p, test_v)\n",
    "test_behavioral_embedding[[0,1,2,3,4,10]] =  test_behavioral_embedding[[0,1,2,3,4,10]]/1000\n",
    "test_text = option_prompt_generate(test_p, test_v)\n",
    "print(f\"test text : {test_text}\")\n",
    "model_name = 'text-embedding-ada-002'\n",
    "tmp_embeddings = get_embeddings(test_text,model_name)\n",
    "tmp_text_embeddings = tmp_embeddings.data[0].embedding\n",
    "tmp_text_embeddings = torch.tensor(tmp_text_embeddings).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    tmp_text_shared_embedding = model(tmp_text_embeddings )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8f463",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(f\"test behavioral embedding: {test_behavioral_embedding}\")\n",
    "print(f\"test text shared embedding: {tmp_text_shared_embedding}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
